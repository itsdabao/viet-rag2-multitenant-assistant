# Force provider selection (optional)
# LLM_PROVIDER=groq | gemini | openai | none
LLM_PROVIDER=groq

# Primary (recommended): Groq (OpenAI-compatible)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=meta-llama/llama-4-scout-17b-16e-instruct
GROQ_BASE_URL=https://api.groq.com/openai/v1

# Optional: LlamaParse (Modern Ingestion cho PDF phức tạp)
# LLAMA_CLOUD_API_KEY=your_llama_cloud_key_here

# Optional fallback: Gemini
# GOOGLE_API_KEY=your_google_api_key_here
# GEMINI_MODEL=gemini-2.5-flash-lite

# Optional fallback: OpenAI
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4o-mini

# --- Postgres (Day 6-7 persistent memory) ---
# For local dev:
# DATABASE_URL=postgresql+psycopg2://admin:123@localhost:5432/agent_memory
# If running app inside another Docker container on the same compose network:
# DATABASE_URL=postgresql+psycopg2://admin:123@db:5432/agent_memory
DATABASE_URL=

# Memory controls (apply to rolling_summary + last N turns)
MEMORY_ENABLED=1
MEMORY_LAST_TURNS=6
MEMORY_BUDGET_TOKENS=1000
MEMORY_SUMMARY_ENABLED=1
